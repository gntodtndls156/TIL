---
tags:
  - AI
Completed: true
---
# ğŸ’¡

> [!info] ê³¼ì œ ë‚´ìš©
> **ì‚¬íšŒì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì£¼ì œë¥¼ ì„ ì •í•˜ì—¬ ì¸ê³µì§€ëŠ¥ í”„ë¡œê·¸ë¨ì„ ê°œë°œí•˜ê³  ë³´ê³ ì„œì™€ ì†ŒìŠ¤ì½”ë“œë¥¼ ì œì¶œí•˜ì„¸ìš”.**

ì²­ê° ì¥ì• ê°€ ìˆëŠ” ë³¸ì¸ì€ ìˆ˜ì—… ë‚´ìš©ì„ ì™„ì „íˆ ì´í•´í•˜ì§€ ëª» í•˜ì—¬, ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ ì´í•´ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¸í„°ë„·ì„ ìµœëŒ€í•œ í™œìš©í•´ í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ ë³´ê³ ì í•©ë‹ˆë‹¤.

ë˜í•œ, ì¶”í›„ì— ì°¸ê³ í•˜ì—¬ ë³´ë‹¤ ë” ë‚˜ì€ ì¸ê³µì§€ëŠ¥ í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ê¸° ìœ„í•´ ê¸°ë¡í•©ë‹ˆë‹¤.
# Step
### ê¸°ë³¸

ê°„ë‹¨í•œ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ êµ¬í˜„í•˜ì—¬ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

```python title:sample
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# ì˜ˆì œ ë°ì´í„° ìƒì„±
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# ë°ì´í„° ì‹œê°í™”
plt.scatter(X, y)
plt.xlabel('X')
plt.ylabel('y')
plt.title('Sample Data')
plt.show()

# ë°ì´í„° ë¶„í•  (í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ì„ í˜• íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡
y_pred = model.predict(X_test)

# ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

# ê²°ê³¼ ì‹œê°í™”
plt.scatter(X_test, y_test, label='Actual')
plt.scatter(X_test, y_pred, label='Predicted')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression Results')
plt.legend()
plt.show()
```

### ì£¼ì œ ì •í•˜ê¸°

í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ ë³´ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. 

ìš”ì¦˜ ì‚¬íšŒëŠ” SNS ë˜ëŠ” ë©”ì‹œì§€ë¥¼ í†µí•´ ì»¤ë®¤ë‹ˆí‹°ì¼€ì´ì…˜ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. 
ì½”ë¡œë‚˜ ì‹œì ˆ ë¹„ëŒ€ë©´ìœ¼ë¡œ ëŒ€í™”í•˜ë ¤ë‹ˆ ìƒëŒ€ë°©ì´ ì–¼êµ´ í‘œì •ì„ ì–´ë–»ê²Œ ì§€ìœ¼ë©´ì„œ ë¬¸ì¥ì„ ì‘ì„±í•˜ì˜€ëŠ”ê°€?, ë¬¸ì¥ì— ì–´ë–¤ ê°ì •ì´ ì‹¤ë ¸ëŠ”ì§€, ì¥ë‚œìœ¼ë¡œ í•œ ë§ì¸ì§€, ì‚¬ì‹¤ëŒ€ë¡œ ë§í•œ ê²ƒì¸ì§€ ì•Œ ìˆ˜ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.
ê·¸ëŸ° ê³„ê¸°ë¡œ ì„œë¡œ ì˜¤í•´í•˜ê¸°ê°€ ì‰½ìƒì´ê³  ê´€ê³„ê°€ ëª¨ë˜ì„± ê°™ì´ ë¬´ë„ˆì§€ê¸°ë„ í•©ë‹ˆë‹¤. 

- ê¸°ë³¸ì ì¸ ê¸°ëŠ¥:
	1. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë‚˜ ë¬¸ì¥ì„ ì…ë ¥ ë°›ìŠµë‹ˆë‹¤.
	2. ì¸ê³µì§€ëŠ¥ í”„ë¡œê·¸ë¨ì´ ê·¸ ë¬¸ì¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.
	3. ì´ ë¬¸ì¥ì— ë¶€ì •ì ì´ê±°ë‚˜ ê¸ì •ì ì¸ ê°ì •ì´ ì‹¤ì—ˆëŠ”ì§€ íŒì •í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ

> ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬

TensorFlow ë˜ëŠ” PyTorchê°€ ìˆë‹¤ê³  í•©ë‹ˆë‹¤. í•™êµì—ì„œ TenforFlow ê°€ë¥´ì³¤ê¸° ë•Œë¬¸ì— ì´ê²ƒì„ í™œìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.

ë˜í•œ, TensorflowëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ê³¼ ëª¨ë“ˆì„ ì œê³µí•˜ë¯€ë¡œ ìì—°ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë”°ë¡œ ì±„íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

Tensorflowì˜ NLPë¥¼ Sequential ëª¨ë¸ë¡œ ì±„íƒí–ˆìŠµë‹ˆë‹¤.
ë ˆì´ì–´ë¥¼ ì„ í˜•ìœ¼ë¡œ ìŒ“ì€ êµ¬ì¡°ë¥¼ ê°–ì¶”ê³ , ê° ë ˆì´ì–´ëŠ” ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤. 

> ì„¤ì¹˜

Anaconda í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì„¤ì¹˜í–ˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ `pip`ëª…ë ¹ì–´ê°€ ì•„ë‹Œ `conda`ëª…ë ¹ì–´ë¥¼ í™œìš©í–ˆë‹¤ëŠ” ì  ì£¼ì˜í•˜ì„¸ìš”.

```shell title:LibarayInstall
[pip|conda] install tensorflow
```

### ìì—°ì–´ ì²˜ë¦¬í•  ì¬ë£Œ

ì´ ê¸€ì´ ë¶€ì •ì ì¸ì§€ ê¸ì •ì ì¸ì§€ íŒë‹¨í•˜ëŠ” ì¬ë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤. ë³„í‘œê°€ ë‚®ìœ¼ë©´ ë¶€ì •ì ì¸ ê¸€ì¼ ê²ƒì´ê³ , ë†’ìœ¼ë©´ ë†’ì„ ìˆ˜ë¡ ê¸ì •ì ì¸ ê¸€ì¼ ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ, IMDB ë¦¬ë·°ì™€ ê°™ì€ ì˜í™” ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¦¬ë·°ë¥¼ ê°€ì ¸ì™€ ì¬ë£Œë¡œ ì“°ì´ë©´ ë  ê²ƒì…ë‹ˆë‹¤.

IMDB Datasetì„ ê°€ì ¸ì™€ì•¼ í•˜ë¯€ë¡œ tensorflow ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. â†’ [imdb_reviews Â |Â  TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/imdb_reviews?hl=ko)

Datasetì€ ëŒ€í˜• ì˜í™” ë¦¬ë·° ë°ì´í„° ì„¸íŠ¸ì´ë©°, ì´ì§„ ê°ì • ë¶„ë¥˜ìš© Datasetì…ë‹ˆë‹¤. êµìœ¡ìš©ìœ¼ë¡œ 25,000ê°œì˜ ê·¹ë‹¨ì ì¸ ì˜í™” ë¦¬ë·° ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 25,000ê°œì˜ ì„¸íŠ¸ë¥¼ ì œê³µí•˜ê³ , ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ì¶”ê°€ ë°ì´í„°ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![[Pasted image 20231216200631.png]]

### ê¸°ì´ˆ ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import imdb
```

```python title:Loding_data
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)
```

`num_words=10000`ì€ ë¹ˆë„ê°€ ê°€ì¥ ë†’ì€ 10,000ê°œì˜ ë‹¨ì–´ë§Œì„ ì‚¬ìš©í•˜ë„ë¡ ë°ì´í„°ë¥¼ ì œí•œí•˜ì—¬, ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ ì œê±°í•˜ê³  ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. 

```python
train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data, value=0, padding='post', maxlen=256)
test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data, value=0, padding='post', maxlen=256)
```

`pad_sequences`í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë¦¬ë·°ì˜ ê¸¸ì´ë¥¼ ë™ì¼í•˜ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. ëª¨ë“  ë¦¬ë·°ë¥¼ `maxlen`ì„ í†µí•´ 256ìœ¼ë¡œ íŒ¨ë”©í•˜ê³  ë¶€ì¡±í•œ ë¶€ë¶„ì€ 0ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.

```python
model = models.Sequential()
model.add(layers.Embedding(input_dim=10000, output_dim=16, input_length=256))
model.add(layers.GlobalAveragePooling1D())
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
```

ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. 

Embedding ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ë¥¼ ë°€ì§‘ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , `GlobalAveragePooling1D`ë¥¼ í†µí•´ ê³ ì •ëœ ê¸¸ì´ì˜ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê·¸ í›„ì— Fully Connected ë ˆì´ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì˜ ë³µì¡ì„±ì„ ì¦ê°€ì‹œí‚¤ê³ , ìµœì¢… ì¶œë ¥ì€ ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```

ëª¨ë¸ì„ ì»´íŒŒì¼í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.

`adam` ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ê³ , ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” ì´ì§„ ë¶„ë¥˜ì— ì‚¬ìš©ë˜ëŠ” â€˜binary_crossentropyâ€™ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•´ ì •í™•ë„ `accuracy`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
model.fit(train_data, train_labels, epochs=10, validation_split=0.2, batch_size=512)
```

ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.

`fit` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³ , 10 ì—í¬í¬ ë™ì•ˆ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤. í›ˆë ¨ ë°ì´í„° ì¤‘ 20%ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ë©°, ë°°ì¹˜ í¬ê¸°ëŠ” 512ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.

```python
test_loss, test_acc = model.evaluate(test_data, test_labels)
print(f'Test Accuracy: {test_acc * 100:.2f}%')
```

í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ì •í™•ë„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

### ê°œì„  ì½”ë“œ

> ì—í¬í¬ ì¡°ì •

`epochs = 10`ë¡œ ì¡°ì •í•œ ê²°ê³¼ëŠ” `Test Accuracy: 86.06%` ì…ë‹ˆë‹¤.
`epochs = 15`ë¡œ ì¡°ì •í•œ ê²°ê³¼ëŠ” `Test Accuracy: 87.51%` ì…ë‹ˆë‹¤.
`epochs = 16`ë¡œ ì¡°ì •í•œ ê²°ê³¼ëŠ” `Test Accuracy: 87.74%` ì…ë‹ˆë‹¤.
`epochs = 20`ë¡œ ì¡°ì •í•œ ê²°ê³¼ëŠ” `Test Accuracy: 87.88%` ì…ë‹ˆë‹¤.
`epochs = 21`ë¡œ ì¡°ì •í•œ ê²°ê³¼ëŠ” `Test Accuracy: 87.91%` ì…ë‹ˆë‹¤.
`epochs = 25`ë¡œ ì¡°ì •í•œ ê²°ê³¼ëŠ” `Test Accuracy: 87.97%` ì…ë‹ˆë‹¤.

ì—í¬í¬ì˜ ìˆ«ìê°€ ë†’ì•„ì§ˆ ìˆ˜ë¡ ì •í™•ë¥ ì´ ìœ ì˜ë¯¸í•˜ê²Œ ë†’ì•„ì§€ì§€ ì•Šê²Œ ë©ë‹ˆë‹¤. 
ì˜¤íˆë ¤ ì—í¬í¬ì˜ ìˆ«ìê°€ `30`ì¸ ê²½ìš° **ì •í™•ë¥ ì´ ë–¨ì–´ì§€ëŠ” ê²ƒì„ í™•ì¸**í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 
`Test Accuracy: 87.78%`

> ë‹¤ì–‘í•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©

**SGD**: `epochs = 10`ì˜ ê²½ìš° `Test Accuracy: 50.02%`ì´ê³ , `epochs = 25`ì˜ ê²½ìš° `Test Accuracy: 49.99%`ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.
**SGD with momentum**: `epochs = 10`, `momentum=0.9`ì˜ ê²½ìš° `Test Accuracy: 53.87%`ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.

**Adagrad**: `epochs = 10`ì˜ ê²½ìš° `Test Accuracy: 51.34%`ì´ê³ , `epochs = 25`ì˜ ê²½ìš° `Test Accuracy: 52.76%`ì…ë‹ˆë‹¤. ê·¸ë ‡ê²Œ ìœ ì˜ë¯¸í•˜ê²Œ ìƒìŠ¹í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

**Adamax**: `epochs = 25`ì˜ ê²½ìš° `Test Accuracy: 86.15%`ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.

ì´ë¡œì¨ ê°€ì¥ ë†’ì€ ì •í™•ë¥ ì´ ë‚˜ì™€ì¤€ ì•Œê³ ë¦¬ì¦˜ì€ **Adam**ì¸ ê²ƒìœ¼ë¡œ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

> Dropoutê³¼ ë‰´ëŸ° ë ˆì´ì–´ ì¶”ê°€

```python
model.add(layers.Dense(64, activation='relu')) 
model.add(layers.Dropout(0.5))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dropout(0.5))
```

ê²°ê³¼: `Test Accuracy: 85.58%`

`epochs = 10` ì˜ ê²½ìš° `Test Accuracy: 87.68%`
`epochs = 9`ì˜ ê²½ìš° `Test Accuracy: 87.81%`

> í•™ìŠµë¥  ì¡°ì •

```python
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
```

`optimizer` ë³€ìˆ˜ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

`epochs = 15`ìœ¼ë¡œ `val_loss` ëª¨ë‹ˆí„°ë§ í•´ ë³¸ ê²°ê³¼, `8`ê°€ ê°€ì¥ ì ì€ ê²ƒìœ¼ë¡œ í™•ì¸ë˜ì–´ ì¡°ì • í›„ ê²°ê³¼ë¥¼ ë´…ë‹ˆë‹¤. `epochs = 8`ì˜ ê²½ìš° `Test Accuracy: 88.01%`ê°€ ë‚˜ì™€ì£¼ì—ˆìŠµë‹ˆë‹¤.
# ğŸˆ

```python title:ìµœì¢…
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import imdb

# ë°ì´í„° ë¡œë“œ
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)

# ë°ì´í„° ì „ì²˜ë¦¬: ì‹œí€€ìŠ¤ íŒ¨ë”©
train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data, value=0, padding='post', maxlen=256)
test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data, value=0, padding='post', maxlen=256)

# ëª¨ë¸ ì •ì˜
model = models.Sequential()
model.add(layers.Embedding(input_dim=10000, output_dim=16, input_length=256))
model.add(layers.GlobalAveragePooling1D())

model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation='sigmoid'))

# ëª¨ë¸ ì»´íŒŒì¼
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy']) # adam

# ëª¨ë¸ í›ˆë ¨
model.fit(train_data, train_labels, epochs=8, validation_split=0.2, batch_size=512) # 25

# ëª¨ë¸ í‰ê°€
test_loss, test_acc = model.evaluate(test_data, test_labels)
print(f'Test Accuracy: {test_acc * 100:.2f}%')
```

![[Pasted image 20231217130315.png]]